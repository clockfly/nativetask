Index: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MapTask.java
===================================================================
--- hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MapTask.java
+++ hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MapTask.java
@@ -57,6 +57,7 @@
 import org.apache.hadoop.mapred.IFile.Writer;
 import org.apache.hadoop.mapred.Merger.Segment;
 import org.apache.hadoop.mapred.SortedRanges.SkipRangeIterator;
+import org.apache.hadoop.mapred.TaskDelegation.MapTaskDelegator;
 import org.apache.hadoop.mapreduce.JobContext;
 import org.apache.hadoop.mapreduce.MRJobConfig;
 import org.apache.hadoop.mapreduce.TaskAttemptContext;
@@ -337,7 +338,15 @@
       return;
     }
 
-    if (useNewApi) {
+    MapTaskDelegator mapTaskDelegator = TaskDelegation
+        .getMapTaskDelegator(umbilical, reporter, job);
+
+    if (null != mapTaskDelegator) {
+      mapTaskDelegator.run(
+          this.getTaskID(),
+          getSplitDetails(new Path(splitMetaInfo.getSplitLocation()),
+              splitMetaInfo.getStartOffset()));
+    } else if (useNewApi) {
       runNewMapper(job, splitMetaInfo, umbilical, reporter);
     } else {
       runOldMapper(job, splitMetaInfo, umbilical, reporter);
@@ -386,11 +395,19 @@
        ReflectionUtils.newInstance(
                         job.getClass(JobContext.MAP_OUTPUT_COLLECTOR_CLASS_ATTR,
                         MapOutputBuffer.class, MapOutputCollector.class), job);
-    LOG.info("Map output collector class = " + collector.getClass().getName());
     MapOutputCollector.Context context =
                            new MapOutputCollector.Context(this, job, reporter);
-    collector.init(context);
-    return collector;
+
+    try {
+      collector.init(context);
+    } catch (IOException e) {
+      LOG.warn("Nativetask falling back to Java MapOutputCollector");
+      collector = new MapOutputBuffer();
+      collector.init(context);
+    } finally {
+      LOG.info("Map output collector class = " + collector.getClass().getName());
+      return collector;
+    }
   }
 
   @SuppressWarnings("unchecked")
Index: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java
===================================================================
--- hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java
+++ hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java
@@ -47,6 +47,7 @@
 import org.apache.hadoop.io.compress.CompressionCodec;
 import org.apache.hadoop.io.compress.DefaultCodec;
 import org.apache.hadoop.mapred.SortedRanges.SkipRangeIterator;
+import org.apache.hadoop.mapred.TaskDelegation.ReduceTaskDelegator;
 import org.apache.hadoop.mapreduce.MRConfig;
 import org.apache.hadoop.mapreduce.TaskAttemptContext;
 import org.apache.hadoop.mapreduce.TaskCounter;
@@ -401,7 +402,13 @@ public void run(JobConf job, final TaskUmbilicalProtocol umbilical)
     Class valueClass = job.getMapOutputValueClass();
     RawComparator comparator = job.getOutputValueGroupingComparator();
 
-    if (useNewApi) {
+    ReduceTaskDelegator reduceDelegator = TaskDelegation.getReduceTaskDelegator(umbilical,
+        reporter, job);
+
+    if (null != reduceDelegator) {
+      reduceDelegator.run(this.getTaskID(), rIter, comparator, keyClass, valueClass);
+
+    } else if (useNewApi) {
       runNewReducer(job, umbilical, reporter, rIter, comparator, 
                     keyClass, valueClass);
     } else {
Index: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/TaskDelegation.java
===================================================================
--- hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/TaskDelegation.java	
+++ hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/TaskDelegation.java
@@ -0,0 +1,124 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.mapred;
+
+import java.io.IOException;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.io.RawComparator;
+import org.apache.hadoop.mapred.Task.TaskReporter;
+import org.apache.hadoop.util.ReflectionUtils;
+
+public class TaskDelegation {
+
+  private static final Log LOG = LogFactory.getLog(TaskDelegation.class);
+  
+  public final static String MAP_TASK_DELEGATPR = "mapreduce.map.task.delegator.class";
+  public final static String REDUCE_TASK_DELEGATPR = "mapreduce.reduce.task.delegator.class";
+  public final static String MAP_OUTPUT_COLLECTOR_DELEGATPR = "mapreduce.map.output.collector.delegator.class";  
+
+  /**
+   * inteface for map task delegator
+   *
+   */
+  public static interface MapTaskDelegator {
+    
+    public void init(TaskUmbilicalProtocol umbilical, TaskReporter reporter, Configuration conf) 
+        throws Exception;
+    
+    public void run(TaskAttemptID taskID,  
+        Object split)
+            throws IOException;
+  }
+  
+  /**
+   * inteface for map reduce task delegator
+   *
+   */
+  public static interface ReduceTaskDelegator {
+
+    public void init(TaskUmbilicalProtocol umbilical, TaskReporter reporter, Configuration conf) 
+        throws Exception;
+    
+    public void run(TaskAttemptID taskID, 
+        RawKeyValueIterator rIter, RawComparator comparator, 
+        Class keyClass, Class valueClass)
+        throws IOException;
+  }
+
+  public static MapTaskDelegator getMapTaskDelegator(TaskUmbilicalProtocol protocol
+      , TaskReporter reporter, JobConf job) {
+    String delegateMapClazz = job.get(MAP_TASK_DELEGATPR, null);
+    if (null == delegateMapClazz || delegateMapClazz.isEmpty()
+        || delegateMapClazz.equals("dummy")) {
+      LOG.info("MapTaskDelegator is not defined");
+      return null;
+    }
+    
+    MapTaskDelegator delegator = null;
+    try {
+      Class<? extends MapTaskDelegator> delegatorClass = (Class<? extends MapTaskDelegator>) 
+          job.getClass(MAP_TASK_DELEGATPR, null);
+      if (null == delegatorClass) {
+        LOG.info("MapTaskDelegator class cannot be load " + delegateMapClazz);
+        return null;
+      }
+      delegator = ReflectionUtils.newInstance(delegatorClass, job);
+      delegator.init(protocol, reporter, job);
+      LOG.info("MapTaskDelegator " + delegateMapClazz + " is enabled");
+    }
+    catch(Exception e) {
+      LOG.error("MapTaskDelegator " + delegateMapClazz + " is not enabled", e);
+      return null;
+    }
+    return delegator;
+  }
+
+
+  public static ReduceTaskDelegator getReduceTaskDelegator(TaskUmbilicalProtocol protocol
+      , TaskReporter reporter, JobConf job) {
+    String delegateReducerClazz = job.get(REDUCE_TASK_DELEGATPR, null);
+    if (null == delegateReducerClazz || delegateReducerClazz.isEmpty() 
+        || delegateReducerClazz.equals("dummy")) {
+      LOG.info("Reduce task Delegator not defined");
+      return null;
+    }
+    
+    ReduceTaskDelegator delegator = null;
+    try {
+      Class<? extends ReduceTaskDelegator> delegatorClass = (Class<? extends ReduceTaskDelegator>) 
+          job.getClass(REDUCE_TASK_DELEGATPR, null);
+      if (null == delegatorClass) {
+        LOG.info("Reduce task Delegator class cannot be load " + delegateReducerClazz);
+        return null;
+      }
+      delegator = ReflectionUtils.newInstance(delegatorClass, job);
+      delegator.init(protocol, reporter, job);
+      LOG.info("ReduceTaskDelegator " + delegateReducerClazz + " is enabled");
+    }
+    catch(Exception e) {
+      LOG.warn("ReduceTaskDelegator " + delegateReducerClazz + " is not enabled", e);
+      return null;
+    }
+    return delegator;
+  }
+
+}

Index: hadoop-dist/pom.xml
===================================================================
--- hadoop-dist/pom.xml
+++ hadoop-dist/pom.xml
@@ -122,6 +122,7 @@
                       run cp -r $ROOT/hadoop-hdfs-project/hadoop-hdfs-nfs/target/hadoop-hdfs-nfs-${project.version}/* .
                       run cp -r $ROOT/hadoop-yarn-project/target/hadoop-yarn-project-${project.version}/* .
                       run cp -r $ROOT/hadoop-mapreduce-project/target/hadoop-mapreduce-${project.version}/* .
+                      run cp -r $ROOT/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/hadoop-mapreduce-client-nativetask-${project.version}/* .
                       run cp -r $ROOT/hadoop-tools/hadoop-tools-dist/target/hadoop-tools-dist-${project.version}/* .
                       echo
                       echo "Hadoop dist layout available at: ${project.build.directory}/hadoop-${project.version}"
Index: hadoop-mapreduce-project/hadoop-mapreduce-client/pom.xml
===================================================================
--- hadoop-mapreduce-project/hadoop-mapreduce-client/pom.xml
+++ hadoop-mapreduce-project/hadoop-mapreduce-client/pom.xml
@@ -195,5 +195,6 @@
     <module>hadoop-mapreduce-client-jobclient</module>
     <module>hadoop-mapreduce-client-hs</module>
     <module>hadoop-mapreduce-client-hs-plugins</module>
+    <module>hadoop-mapreduce-client-nativetask</module>
   </modules>
 </project>
Index: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/Text.java
===================================================================
--- hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/Text.java
+++ hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/Text.java
@@ -226,6 +226,10 @@
     this.length = len;
   }
 
+  public void setLength(int len) {
+    this.length = len;
+  }
+
   /**
    * Append a range of bytes to the end of the given text
    * @param utf8 the data to copy from
@@ -260,7 +264,7 @@
    * @param len the number of bytes we need
    * @param keepData should the old data be kept
    */
-  private void setCapacity(int len, boolean keepData) {
+  public void setCapacity(int len, boolean keepData) {
     if (bytes == null || bytes.length < len) {
       if (bytes != null && keepData) {
         bytes = Arrays.copyOf(bytes, Math.max(len,length << 1));
